{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from category_encoders import TargetEncoder, OrdinalEncoder\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class ChurnAnalyzer:\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"Initialize the churn analyzer with data path\"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.df = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "\n",
    "    def load_and_explore_data(self):\n",
    "        \"\"\"Load data and perform initial exploration\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"CUSTOMER CHURN PREDICTION ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Load data\n",
    "        self.df = pd.read_csv(self.data_path)\n",
    "        print(f\"\\n📊 Dataset Shape: {self.df.shape}\")\n",
    "        print(f\"📋 Features: {self.df.shape[1]} columns\")\n",
    "        print(f\"📈 Samples: {self.df.shape[0]} rows\")\n",
    "\n",
    "        # Basic info about target variable\n",
    "        churn_counts = self.df[\"Target_ChurnFlag\"].value_counts()\n",
    "        churn_rate = (churn_counts[1] / len(self.df)) * 100 if 1 in churn_counts else 0\n",
    "\n",
    "        print(\"\\n🎯 TARGET VARIABLE ANALYSIS:\")\n",
    "        print(f\"   • Churn Rate: {churn_rate:.2f}%\")\n",
    "        print(f\"   • Churned Customers: {churn_counts.get(1, 0)}\")\n",
    "        print(f\"   • Retained Customers: {churn_counts.get(0, 0)}\")\n",
    "\n",
    "        # Missing values analysis\n",
    "        missing_data = self.df.isnull().sum()\n",
    "        missing_percent = (missing_data / len(self.df)) * 100\n",
    "        missing_df = pd.DataFrame(\n",
    "            {\"Missing_Count\": missing_data, \"Missing_Percentage\": missing_percent}\n",
    "        ).sort_values(\"Missing_Percentage\", ascending=False)\n",
    "\n",
    "        print(\"\\n MISSING DATA ANALYSIS:\")\n",
    "        print(f\"   • Features with missing data: {(missing_data > 0).sum()}\")\n",
    "        if (missing_data > 0).sum() > 0:\n",
    "            print(\"   • Top 5 features with most missing data:\")\n",
    "            print(missing_df.head().to_string())\n",
    "\n",
    "        return self.df.head()\n",
    "\n",
    "    def visualize_data(self):\n",
    "        \"\"\"Create visualizations for data exploration\"\"\"\n",
    "        print(\"\\n CREATING VISUALIZATIONS...\")\n",
    "\n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle(\"Customer Churn Data Exploration\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "        # 1. Churn distribution\n",
    "        churn_counts = self.df[\"Target_ChurnFlag\"].value_counts()\n",
    "        labels = [\"Retained\", \"Churned\"]\n",
    "        axes[0, 0].pie(\n",
    "            churn_counts.values, labels=labels, autopct=\"%1.1f%%\", startangle=90\n",
    "        )\n",
    "        axes[0, 0].set_title(\"Churn Distribution\")\n",
    "\n",
    "        # 2. Missing data heatmap (top 20 features)\n",
    "        missing_data = self.df.isnull().sum().sort_values(ascending=False).head(20)\n",
    "        if len(missing_data) > 0:\n",
    "            axes[0, 1].barh(range(len(missing_data)), missing_data.values)\n",
    "            axes[0, 1].set_yticks(range(len(missing_data)))\n",
    "            axes[0, 1].set_yticklabels(missing_data.index, fontsize=8)\n",
    "            axes[0, 1].set_title(\"Top 20 Features with Missing Data\")\n",
    "            axes[0, 1].set_xlabel(\"Missing Count\")\n",
    "\n",
    "        # 3. Feature correlation with target (sample)\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        numeric_cols = [col for col in numeric_cols if col != \"Target_ChurnFlag\"][:15]\n",
    "\n",
    "        if len(numeric_cols) > 0:\n",
    "            correlations = []\n",
    "            for col in numeric_cols:\n",
    "                try:\n",
    "                    corr = self.df[col].corr(self.df[\"Target_ChurnFlag\"])\n",
    "                    if not np.isnan(corr):\n",
    "                        correlations.append((col, abs(corr)))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating correlation for {col}: {e}\")\n",
    "            if correlations:\n",
    "                correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "                features, corr_values = zip(*correlations[:10])\n",
    "\n",
    "                axes[1, 0].barh(range(len(features)), corr_values)\n",
    "                axes[1, 0].set_yticks(range(len(features)))\n",
    "                axes[1, 0].set_yticklabels(features, fontsize=8)\n",
    "                axes[1, 0].set_title(\"Top 10 Features - Correlation with Churn\")\n",
    "                axes[1, 0].set_xlabel(\"Absolute Correlation\")\n",
    "\n",
    "        # 4. Data types distribution\n",
    "        dtype_counts = self.df.dtypes.value_counts()\n",
    "        axes[1, 1].pie(\n",
    "            dtype_counts.values, labels=dtype_counts.index, autopct=\"%1.1f%%\"\n",
    "        )\n",
    "        axes[1, 1].set_title(\"Data Types Distribution\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess data for modeling\"\"\"\n",
    "        print(\"\\n PREPROCESSING DATA...\")\n",
    "\n",
    "        # --- Step 1: Remove Duplicate and Unwanted Columns ---\n",
    "        print(\"   • Identifying duplicate columns...\")\n",
    "        columns_to_remove = {\"UID\"}\n",
    "\n",
    "        # Detect duplicate columns\n",
    "        duplicates = []\n",
    "        columns = self.df.columns\n",
    "\n",
    "        for i in range(len(columns)):\n",
    "            for j in range(i + 1, len(columns)):\n",
    "                if self.df[columns[i]].equals(self.df[columns[j]]):\n",
    "                    duplicates.append((columns[i], columns[j]))\n",
    "\n",
    "        # Prepare columns to drop\n",
    "        cols_to_drop = {dup[1] for dup in duplicates} | columns_to_remove\n",
    "        self.df.drop(columns=cols_to_drop, errors=\"ignore\", inplace=True)\n",
    "\n",
    "        self.df = self.df.dropna(axis=1, how=\"any\")\n",
    "        self.df = self.df.drop_duplicates()\n",
    "\n",
    "        constant_cols = [col for col in self.df.columns if self.df[col].nunique() == 1]\n",
    "        self.df.drop(columns=constant_cols, inplace=True)\n",
    "        print(f\" • Dropped {len(cols_to_drop)} columns (duplicates and UID)\")\n",
    "\n",
    "        print(f\"  Shape: {self.df.shape}\")\n",
    "\n",
    "        # --- Step 5: Categorical Encoding ---\n",
    "        print(\"\\n   • Encoding categorical variables...\")\n",
    "\n",
    "        # # Target encode high-cardinality features\n",
    "        high_card_cols = [\"X150\", \"X151\", \"X154\", \"X155\"]\n",
    "        high_card_cols = [\n",
    "            col for col in high_card_cols if col in self.df.columns\n",
    "        ]  # Ensure they exist\n",
    "        if high_card_cols:\n",
    "            encoder = TargetEncoder(cols=high_card_cols, smoothing=10)\n",
    "            self.df = encoder.fit_transform(self.df, self.df[\"Target_ChurnFlag\"])\n",
    "            print(f\"   • Encoded {len(high_card_cols)} high-cardinality features with Target Encoding\")\n",
    "            joblib.dump(encoder, \"target_encoder.pkl\")\n",
    "\n",
    "        # # Ordinal encode ordered categories\n",
    "        ordinal_cols = [\"X18\"]\n",
    "        ordinal_cols = [col for col in ordinal_cols if col in self.df.columns]  # Ensure they exist\n",
    "        if ordinal_cols:\n",
    "            encoder = OrdinalEncoder(cols=ordinal_cols) \n",
    "            self.df[ordinal_cols] = encoder.fit_transform(self.df[ordinal_cols], self.df[\"Target_ChurnFlag\"])\n",
    "            joblib.dump(encoder, \"ordinal_encoder.pkl\")  # Save the encoder\n",
    "\n",
    "        print(f\"   • Encoded {len(ordinal_cols)} ordinal features with Ordinal Encoding\")\n",
    "\n",
    "        # One-hot encode low-cardinality nominal features\n",
    "        nominal_cols = [\"X0\", \"X152\", \"X156\", \"X157\", \"X158\"]\n",
    "        nominal_cols = [\n",
    "            col for col in nominal_cols if col in self.df.columns\n",
    "        ]  # Ensure they exist\n",
    "        if nominal_cols:\n",
    "            self.df = pd.get_dummies(\n",
    "                self.df,\n",
    "                columns=nominal_cols,\n",
    "                drop_first=True,  # Avoids dummy trap\n",
    "                prefix_sep=\"_\",\n",
    "            )\n",
    "        print(\n",
    "            f\"   • Encoded {len(nominal_cols)} nominal features with One-Hot Encoding\"\n",
    "        )\n",
    "\n",
    "        for col in [\"X2\", \"X3\", \"X5\", \"X6\", \"X30\", \"X31\"]:\n",
    "            if col in self.df.columns:\n",
    "                print(f\"   • Processing date column: {col}\")\n",
    "                self.df[col] = pd.to_datetime(self.df[col])\n",
    "                self.df[f\"{col}_days_since\"] = (\n",
    "                    pd.Timestamp.now() - self.df[col]\n",
    "                ).dt.days\n",
    "                self.df = self.df.drop(columns=col)  # Remove original date column\n",
    "        print(\"   • Processed date columns to 'days since' format\")\n",
    "\n",
    "        X = self.df.drop(columns=[\"Target_ChurnFlag\"])\n",
    "        y = self.df[\"Target_ChurnFlag\"]\n",
    "        print(f\"   • Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "\n",
    "        # print(\"\\n   • Checking feature correlation with target variable...\")\n",
    "\n",
    "        # # Check correlation with target variable\n",
    "        # corr = pd.concat([pd.DataFrame(X), pd.DataFrame(y)], axis=1).corr()[\n",
    "        #     \"Target_ChurnFlag\"\n",
    "        # ].abs().sort_values(ascending=False)\n",
    "        # high_corr_features = corr[1:][corr[1:] > 0.1].index  # Only feature names\n",
    "        # X = X.drop(columns=high_corr_features)  # Drop highly correlated features\n",
    "        # print(f\"   • Dropped {len(high_corr_features)} highly correlated features\")\n",
    "        # print(f\"   • Remaining features shape: {X.shape}\")\n",
    "\n",
    "        # --- Step 6: Feature Scaling ---\n",
    "        print(\"   • Scaling features...\")\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        X = self.scaler.fit_transform(X)\n",
    "\n",
    "        joblib.dump(self.scaler, \"scaler.pkl\")  # Save the scaler for future \n",
    "        \n",
    "        print(\"   • Features scaled using StandardScaler\")\n",
    "        print(f\"   • Scaled features shape: {X.shape}\")\n",
    "        \n",
    "        # Verify no NaN values after scaling\n",
    "        if np.isnan(X).any():\n",
    "            print(\"   ❌ NaN values found in scaled features\")\n",
    "        else:\n",
    "            print(\"   • No NaN values in scaled features\")\n",
    "        # Convert scaled features back to DataFrame\n",
    "\n",
    "        # # --- Step 7: Train-Test Split ---\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        print(\"\\n   ✅ Preprocessing complete!\")\n",
    "        print(f\"   • Final training set: {self.X_train.shape}\")\n",
    "        print(f\"   • Final test set: {self.X_test.shape}\")\n",
    "\n",
    "        return X.shape\n",
    "\n",
    "    def train_models(self):\n",
    "        \"\"\"Train multiple models\"\"\"\n",
    "        print(\"\\n🤖 TRAINING MODELS...\")\n",
    "        ratio = (len(self.y_train) - sum(self.y_train)) / sum(self.y_train)\n",
    "\n",
    "        # Define models\n",
    "        models = {\n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "            \"LightGBM\": lgb.LGBMClassifier(\n",
    "                objective=\"binary\",\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.02,\n",
    "                num_leaves=127,\n",
    "                max_depth=-1,\n",
    "                min_child_samples=100,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.2,\n",
    "                reg_lambda=0.2,\n",
    "                scale_pos_weight=ratio,\n",
    "                boosting_type=\"dart\",\n",
    "                metric=\"auc\",\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        print(\n",
    "            f\"   • Using scale_pos_weight = {ratio:.2f} for LightGBM to handle class imbalance\"\n",
    "        )\n",
    "\n",
    "        # Train and evaluate each model\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\n   Training {name}...\")\n",
    "\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            y_pred_proba = model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = model.score(\n",
    "                self.X_test , self.y_test\n",
    "            )\n",
    "            auc_score = roc_auc_score(self.y_test, y_pred_proba)\n",
    "\n",
    "            # Cross-validation score\n",
    "            cv_scores = cross_val_score(\n",
    "                model,\n",
    "                self.X_train if name != \"SVM\" else self.X_train_scaled,\n",
    "                self.y_train,\n",
    "                cv=5,\n",
    "                scoring=\"roc_auc\",\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            self.models[name] = model\n",
    "            self.results[name] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"auc_score\": auc_score,\n",
    "                \"cv_mean\": cv_scores.mean(),\n",
    "                \"cv_std\": cv_scores.std(),\n",
    "                \"predictions\": y_pred,\n",
    "                \"probabilities\": y_pred_proba,\n",
    "            }\n",
    "\n",
    "            print(f\"     ✓ Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"     ✓ AUC Score: {auc_score:.4f}\")\n",
    "            print(f\"     ✓ CV Score: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "\n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate and compare models\"\"\"\n",
    "        print(\"\\n MODEL EVALUATION RESULTS:\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Create results summary\n",
    "        results_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Model\": list(self.results.keys()),\n",
    "                \"Accuracy\": [\n",
    "                    self.results[model][\"accuracy\"] for model in self.results.keys()\n",
    "                ],\n",
    "                \"AUC Score\": [\n",
    "                    self.results[model][\"auc_score\"] for model in self.results.keys()\n",
    "                ],\n",
    "                \"CV Mean\": [\n",
    "                    self.results[model][\"cv_mean\"] for model in self.results.keys()\n",
    "                ],\n",
    "                \"CV Std\": [\n",
    "                    self.results[model][\"cv_std\"] for model in self.results.keys()\n",
    "                ],\n",
    "            }\n",
    "        ).sort_values(\"AUC Score\", ascending=False)\n",
    "\n",
    "        print(results_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "        # Best model\n",
    "        best_model_name = results_df.iloc[0][\"Model\"]\n",
    "        print(f\"\\n BEST MODEL: {best_model_name}\")\n",
    "        print(f\"   • AUC Score: {self.results[best_model_name]['auc_score']:.4f}\")\n",
    "        print(f\"   • Accuracy: {self.results[best_model_name]['accuracy']:.4f}\")\n",
    "\n",
    "        # Detailed evaluation for best model\n",
    "        print(f\"\\n📋 DETAILED EVALUATION - {best_model_name}:\")\n",
    "        y_pred = self.results[best_model_name][\"predictions\"]\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        print(cm)\n",
    "\n",
    "        return best_model_name, results_df\n",
    "\n",
    "    def create_model_comparison_plots(self):\n",
    "        \"\"\"Create visualization comparing models\"\"\"\n",
    "        print(\"\\n CREATING MODEL COMPARISON PLOTS...\")\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle(\"Model Performance Comparison\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "        # 1. AUC Score comparison\n",
    "        models = list(self.results.keys())\n",
    "        auc_scores = [self.results[model][\"auc_score\"] for model in models]\n",
    "\n",
    "        axes[0, 0].bar(models, auc_scores, color=\"skyblue\")\n",
    "        axes[0, 0].set_title(\"AUC Score Comparison\")\n",
    "        axes[0, 0].set_ylabel(\"AUC Score\")\n",
    "        axes[0, 0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        # 2. Accuracy comparison\n",
    "        accuracies = [self.results[model][\"accuracy\"] for model in models]\n",
    "        axes[0, 1].bar(models, accuracies, color=\"lightcoral\")\n",
    "        axes[0, 1].set_title(\"Accuracy Comparison\")\n",
    "        axes[0, 1].set_ylabel(\"Accuracy\")\n",
    "        axes[0, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        # 3. ROC Curves\n",
    "        for model_name in models:\n",
    "            y_pred_proba = self.results[model_name][\"probabilities\"]\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)\n",
    "            auc_score = self.results[model_name][\"auc_score\"]\n",
    "            axes[1, 0].plot(fpr, tpr, label=f\"{model_name} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "        axes[1, 0].plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
    "        axes[1, 0].set_xlabel(\"False Positive Rate\")\n",
    "        axes[1, 0].set_ylabel(\"True Positive Rate\")\n",
    "        axes[1, 0].set_title(\"ROC Curves\")\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "\n",
    "        # 4. Cross-validation scores\n",
    "        cv_means = [self.results[model][\"cv_mean\"] for model in models]\n",
    "        cv_stds = [self.results[model][\"cv_std\"] for model in models]\n",
    "\n",
    "        axes[1, 1].bar(models, cv_means, yerr=cv_stds, capsize=5, color=\"lightgreen\")\n",
    "        axes[1, 1].set_title(\"Cross-Validation Scores\")\n",
    "        axes[1, 1].set_ylabel(\"CV Score (Mean ± Std)\")\n",
    "        axes[1, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def generate_insights(self):\n",
    "        \"\"\"Generate insights\"\"\"\n",
    "\n",
    "        # Churn rate analysis\n",
    "        churn_rate = (self.df[\"Target_ChurnFlag\"].sum() / len(self.df)) * 100\n",
    "\n",
    "        print(\"📈 CURRENT SITUATION:\")\n",
    "        print(f\"   • Overall churn rate: {churn_rate:.2f}%\")\n",
    "        print(f\"   • Total customers analyzed: {len(self.df):,}\")\n",
    "        print(f\"   • Customers at risk: {self.df['Target_ChurnFlag'].sum():,}\")\n",
    "\n",
    "        # Model performance insights\n",
    "        best_model = max(\n",
    "            self.results.keys(), key=lambda x: self.results[x][\"auc_score\"]\n",
    "        )\n",
    "        best_auc = self.results[best_model][\"auc_score\"]\n",
    "\n",
    "        print(\"\\n MODEL PERFORMANCE:\")\n",
    "        print(f\"   • Best performing model: {best_model}\")\n",
    "        print(f\"   • Prediction accuracy: {best_auc:.1%}\")\n",
    "        print(f\"   • Model can identify {best_auc:.1%} of churners correctly\")\n",
    "\n",
    "        return {\n",
    "            \"churn_rate\": churn_rate,\n",
    "            \"best_model\": best_model,\n",
    "            \"best_auc\": best_auc,\n",
    "            \"total_customers\": len(self.df),\n",
    "            \"churned_customers\": self.df[\"Target_ChurnFlag\"].sum(),\n",
    "        }\n",
    "\n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "        print(\"🚀 Starting Complete Churn Analysis Pipeline...\\n\")\n",
    "\n",
    "        # Step 1: Load and explore data\n",
    "        sample_data = self.load_and_explore_data()\n",
    "\n",
    "        # Step 2: Visualize data\n",
    "        self.visualize_data()\n",
    "\n",
    "        # Step 3: Preprocess data\n",
    "        data_shape = self.preprocess_data()\n",
    "\n",
    "        # Step 5: Train models\n",
    "        self.train_models()\n",
    "\n",
    "        # Step 6: Evaluate models\n",
    "        best_model, results_summary = self.evaluate_models()\n",
    "\n",
    "        # Step 7: Create comparison plots\n",
    "        self.create_model_comparison_plots()\n",
    "\n",
    "        # Step 8: Generate insights\n",
    "        insights = self.generate_insights()\n",
    "\n",
    "        print(\"ANALYSIS COMPLETE!\")\n",
    "        print(\"Check the generated plots and results above.\")\n",
    "\n",
    "        return {\n",
    "            \"sample_data\": sample_data,\n",
    "            \"data_shape\": data_shape,\n",
    "            \"best_model\": best_model,\n",
    "            \"results_summary\": results_summary,\n",
    "            \"insights\": insights,\n",
    "        }\n",
    "\n",
    "\n",
    "analyzer = ChurnAnalyzer(\"deepq_ai_assignment1_data.csv\")\n",
    "\n",
    "analyzer.run_complete_analysis()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnPredictor:\n",
    "    def __init__(self):\n",
    "        # Load all the saved components\n",
    "        self.model = joblib.load('lightgbm_model.pkl')\n",
    "        self.scaler = joblib.load('scaler.pkl')\n",
    "        self.target_encoder = joblib.load('target_encoder.pkl')\n",
    "        self.ordinal_encoder = joblib.load('ordinal_encoder.pkl')\n",
    "        \n",
    "        # Load feature names from CSV\n",
    "        try:\n",
    "            self.feature_names = pd.read_csv('features.csv')['Feature'].tolist()\n",
    "        except FileNotFoundError:\n",
    "            raise Exception(\"Feature names file not found. Please ensure 'features.csv' exists.\")\n",
    "        \n",
    "    def preprocess_new_data(self, new_data:pd.DataFrame) :   \n",
    "        \"\"\"Preprocess new data in the same way as training data\"\"\"\n",
    "        # Make a copy to avoid modifying original\n",
    "        processed_data = new_data.copy()\n",
    "        \n",
    "        # 1. Drop the same columns that were dropped during training\n",
    "        columns_to_remove = {\"UID\"}\n",
    "\n",
    "        # Detect duplicate columns\n",
    "        duplicates = []\n",
    "        columns = processed_data.columns\n",
    "\n",
    "        for i in range(len(columns)):\n",
    "            for j in range(i + 1, len(columns)):\n",
    "                if processed_data[columns[i]].equals(processed_data[columns[j]]):\n",
    "                    duplicates.append((columns[i], columns[j]))\n",
    "\n",
    "        # Prepare columns to drop\n",
    "        cols_to_drop = {dup[1] for dup in duplicates} | columns_to_remove\n",
    "        processed_data.drop(columns=cols_to_drop, errors=\"ignore\", inplace=True)\n",
    "\n",
    "        processed_data = processed_data.dropna(axis=1, how=\"any\")\n",
    "\n",
    "        constant_cols = [col for col in processed_data.columns if processed_data[col].nunique() == 1]\n",
    "        processed_data.drop(columns=constant_cols, inplace=True)\n",
    "        \n",
    "        # 2. Handle date columns\n",
    "        date_cols = [\"X2\", \"X3\", \"X5\", \"X6\", \"X30\", \"X31\"]\n",
    "        for col in date_cols:\n",
    "            if col in processed_data.columns:\n",
    "                processed_data[col] = pd.to_datetime(processed_data[col])\n",
    "                processed_data[f\"{col}_days_since\"] = (\n",
    "                    pd.Timestamp.now() - processed_data[col]\n",
    "                ).dt.days\n",
    "                processed_data = processed_data.drop(columns=col)\n",
    "        \n",
    "        # 3. Apply the same encodings\n",
    "        high_card_cols = [\"X150\", \"X151\", \"X154\", \"X155\"]\n",
    "        high_card_cols = [col for col in high_card_cols if col in processed_data.columns]\n",
    "        if high_card_cols:\n",
    "            processed_data = self.target_encoder.transform(processed_data)\n",
    "        \n",
    "        ordinal_cols = [\"X18\"]\n",
    "        ordinal_cols = [col for col in ordinal_cols if col in processed_data.columns]\n",
    "        if ordinal_cols:\n",
    "            processed_data[ordinal_cols] = self.ordinal_encoder.transform(\n",
    "                processed_data[ordinal_cols]\n",
    "            )\n",
    "        \n",
    "        # 4. One-hot encode nominal features\n",
    "        nominal_cols = [\"X0\", \"X152\", \"X156\", \"X157\", \"X158\"]\n",
    "        nominal_cols = [col for col in nominal_cols if col in processed_data.columns]\n",
    "        if nominal_cols:\n",
    "            processed_data = pd.get_dummies(\n",
    "                processed_data,\n",
    "                columns=nominal_cols,\n",
    "                drop_first=True,\n",
    "                prefix_sep=\"_\"\n",
    "            )\n",
    "        \n",
    "        # 5. Ensure we have all expected columns (add missing with 0s)\n",
    "        for col in self.feature_names:\n",
    "            if col not in processed_data.columns:\n",
    "                processed_data[col] = 0\n",
    "        \n",
    "        # 6. Reorder columns to match training data\n",
    "        processed_data = processed_data[self.feature_names]\n",
    "        \n",
    "        # 7. Scale the features\n",
    "        scaled_data = self.scaler.transform(processed_data)\n",
    "        \n",
    "        return scaled_data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class ChurnPredictorApp(ChurnPredictor):\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the predictor with all saved models and preprocessors\"\"\"\n",
    "       \n",
    "\n",
    "    def predict_all_models(self, csv_file):\n",
    "        \"\"\"Make predictions using all three models\"\"\"\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(csv_file.name)\n",
    "            \n",
    "            # Check if file is empty\n",
    "            if df.empty:\n",
    "                return \"Error: The uploaded file is empty.\", None, None, None, None\n",
    "            \n",
    "            # Preprocess the data\n",
    "            processed_data = self.preprocess_new_data(df)\n",
    "            \n",
    "            # Get predictions from all models\n",
    "            predictions = {}\n",
    "            probabilities = {}\n",
    "            \n",
    "            for model_name, model in self.models.items():\n",
    "                pred = model.predict(processed_data)\n",
    "                prob = model.predict_proba(processed_data)[:, 1]\n",
    "                predictions[model_name] = pred\n",
    "                probabilities[model_name] = prob\n",
    "            \n",
    "            # Create results dataframe\n",
    "            results_df = df.copy()\n",
    "            for model_name in self.models.keys():\n",
    "                results_df[f'{model_name}_Prediction'] = predictions[model_name]\n",
    "                results_df[f'{model_name}_Churn_Probability'] = probabilities[model_name]\n",
    "            \n",
    "            # Generate summary statistics\n",
    "            summary_stats = self.generate_summary_stats(predictions, probabilities, len(df))\n",
    "            \n",
    "            # Create visualizations\n",
    "            prob_dist_plot = self.create_probability_distribution_plot(probabilities)\n",
    "            model_comparison_plot = self.create_model_comparison_plot(predictions, probabilities)\n",
    "            churn_risk_plot = self.create_churn_risk_segments_plot(probabilities)\n",
    "            prediction_summary_plot = self.create_prediction_summary_plot(predictions)\n",
    "            \n",
    "            return (\n",
    "                summary_stats,\n",
    "                prob_dist_plot,\n",
    "                model_comparison_plot, \n",
    "                churn_risk_plot,\n",
    "                prediction_summary_plot,\n",
    "                results_df\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing file: {str(e)}\"\n",
    "            return error_msg, None, None, None, None, None\n",
    "\n",
    "    def generate_summary_stats(self, predictions, probabilities, total_samples):\n",
    "        \"\"\"Generate summary statistics\"\"\"\n",
    "        stats = f\"\"\"\n",
    "        📊 **PREDICTION SUMMARY**\n",
    "        \n",
    "        **Dataset Info:**\n",
    "        - Total Customers Analyzed: {total_samples:,}\n",
    "        \n",
    "        **Churn Predictions by Model:**\n",
    "        \"\"\"\n",
    "        \n",
    "        for model_name in predictions.keys():\n",
    "            churn_count = sum(predictions[model_name])\n",
    "            churn_rate = (churn_count / total_samples) * 100\n",
    "            avg_prob = np.mean(probabilities[model_name])\n",
    "            \n",
    "            stats += f\"\"\"\n",
    "        **{model_name}:**\n",
    "        - Predicted Churners: {churn_count:,} ({churn_rate:.1f}%)\n",
    "        - Average Churn Probability: {avg_prob:.3f}\n",
    "        - High Risk Customers (>70% prob): {sum(probabilities[model_name] > 0.7):,}\n",
    "            \"\"\"\n",
    "        \n",
    "        return stats\n",
    "\n",
    "    def create_probability_distribution_plot(self, probabilities):\n",
    "        \"\"\"Create probability distribution plot for all models\"\"\"\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=3,\n",
    "            subplot_titles=list(probabilities.keys()),\n",
    "            horizontal_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "        \n",
    "        for i, (model_name, probs) in enumerate(probabilities.items()):\n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=probs,\n",
    "                    nbinsx=30,\n",
    "                    name=model_name,\n",
    "                    marker_color=colors[i],\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                row=1, col=i+1\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_text=\"Churn Probability Distributions by Model\",\n",
    "            title_x=0.5,\n",
    "            height=400,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Churn Probability\")\n",
    "        fig.update_yaxes(title_text=\"Number of Customers\")\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def create_model_comparison_plot(self, predictions, probabilities):\n",
    "        \"\"\"Create model comparison plot\"\"\"\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=[\n",
    "                'Predicted Churn Counts',\n",
    "                'Average Churn Probabilities', \n",
    "                'High Risk Customers (>70%)',\n",
    "                'Medium Risk Customers (30-70%)'\n",
    "            ],\n",
    "            specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "                   [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    "        )\n",
    "        \n",
    "        model_names = list(predictions.keys())\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "        \n",
    "        # Churn counts\n",
    "        churn_counts = [sum(predictions[model]) for model in model_names]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=model_names, y=churn_counts, name='Churn Count', \n",
    "                   marker_color=colors, text=churn_counts, textposition='auto'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Average probabilities\n",
    "        avg_probs = [np.mean(probabilities[model]) for model in model_names]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=model_names, y=avg_probs, name='Avg Probability',\n",
    "                   marker_color=colors, text=[f'{p:.3f}' for p in avg_probs], \n",
    "                   textposition='auto'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # High risk customers\n",
    "        high_risk = [sum(probabilities[model] > 0.7) for model in model_names]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=model_names, y=high_risk, name='High Risk',\n",
    "                   marker_color=colors, text=high_risk, textposition='auto'),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Medium risk customers\n",
    "        medium_risk = [sum((probabilities[model] >= 0.3) & (probabilities[model] <= 0.7)) \n",
    "                      for model in model_names]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=model_names, y=medium_risk, name='Medium Risk',\n",
    "                   marker_color=colors, text=medium_risk, textposition='auto'),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_text=\"Model Performance Comparison\",\n",
    "            title_x=0.5,\n",
    "            height=600,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def create_churn_risk_segments_plot(self, probabilities):\n",
    "        \"\"\"Create churn risk segmentation plot\"\"\"\n",
    "        # Define risk categories\n",
    "        risk_categories = ['Low Risk (0-30%)', 'Medium Risk (30-70%)', 'High Risk (70%+)']\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        colors = ['#2ECC71', '#F39C12', '#E74C3C']\n",
    "        model_names = list(probabilities.keys())\n",
    "        \n",
    "        for i, model_name in enumerate(model_names):\n",
    "            probs = probabilities[model_name]\n",
    "            low_risk = sum(probs < 0.3)\n",
    "            medium_risk = sum((probs >= 0.3) & (probs < 0.7))\n",
    "            high_risk = sum(probs >= 0.7)\n",
    "            \n",
    "            fig.add_trace(go.Bar(\n",
    "                name=model_name,\n",
    "                x=risk_categories,\n",
    "                y=[low_risk, medium_risk, high_risk],\n",
    "                text=[low_risk, medium_risk, high_risk],\n",
    "                textposition='auto',\n",
    "                marker_color=colors,\n",
    "                opacity=0.8,\n",
    "                yaxis=f'y{i+1}' if i > 0 else 'y',\n",
    "                offsetgroup=i\n",
    "            ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Customer Risk Segmentation by Model',\n",
    "            title_x=0.5,\n",
    "            xaxis_title='Risk Categories',\n",
    "            yaxis_title='Number of Customers',\n",
    "            barmode='group',\n",
    "            height=500,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def create_prediction_summary_plot(self, predictions):\n",
    "        \"\"\"Create prediction summary pie charts\"\"\"\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=3,\n",
    "            specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}, {\"type\": \"pie\"}]],\n",
    "            subplot_titles=list(predictions.keys())\n",
    "        )\n",
    "        \n",
    "        colors = ['#2ECC71', '#E74C3C']  # Green for No Churn, Red for Churn\n",
    "        \n",
    "        for i, (model_name, preds) in enumerate(predictions.items()):\n",
    "            churn_count = sum(preds)\n",
    "            no_churn_count = len(preds) - churn_count\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Pie(\n",
    "                    labels=['No Churn', 'Churn'],\n",
    "                    values=[no_churn_count, churn_count],\n",
    "                    name=model_name,\n",
    "                    marker_colors=colors,\n",
    "                    textinfo='label+percent',\n",
    "                    textposition='auto'\n",
    "                ),\n",
    "                row=1, col=i+1\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_text=\"Churn vs No-Churn Predictions\",\n",
    "            title_x=0.5,\n",
    "            height=400,\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "\n",
    "predictor_app = ChurnPredictorApp()\n",
    "\n",
    "# Create Gradio interface\n",
    "def predict_churn(csv_file):\n",
    "    if csv_file is None:\n",
    "        return \"Please upload a CSV file.\", None, None, None, None, None\n",
    "    \n",
    "    return predictor_app.predict_all_models(csv_file)\n",
    "\n",
    "# Create the Gradio app\n",
    "with gr.Blocks(\n",
    "    title=\"Customer Churn Prediction System\",\n",
    "    theme=gr.themes.Soft(),\n",
    "    css=\"\"\"\n",
    "    .gradio-container {\n",
    "        max-width: 1200px !important;\n",
    "    }\n",
    "    \"\"\"\n",
    ") as app:\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    # 🎯 Customer Churn Prediction System\n",
    "    - **Random Forest**: Ensemble method using multiple decision trees\n",
    "    - **Gradient Boosting**: Sequential ensemble method for improved accuracy  \n",
    "    - **LightGBM**: Optimized gradient boosting framework\n",
    "    \n",
    "\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            csv_input = gr.File(\n",
    "                label=\"📁 Upload CSV File\",\n",
    "                file_types=[\".csv\"],\n",
    "                type=\"filepath\"\n",
    "            )\n",
    "            \n",
    "            predict_btn = gr.Button(\n",
    "                \"🚀 Predict Churn\", \n",
    "                variant=\"primary\", \n",
    "                size=\"lg\"\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        summary_output = gr.Markdown(label=\"📈 Prediction Summary\")\n",
    "    \n",
    "    with gr.Tab(\"📊 Visualizations\"):\n",
    "        with gr.Row():\n",
    "            prob_dist_plot = gr.Plot(label=\"Probability Distributions\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            model_comparison_plot = gr.Plot(label=\"Model Comparison\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            churn_risk_plot = gr.Plot(label=\"Risk Segmentation\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            prediction_summary_plot = gr.Plot(label=\"Prediction Summary\")\n",
    "    \n",
    "    with gr.Tab(\"📋 Detailed Results\"):\n",
    "        results_table = gr.Dataframe(\n",
    "            label=\"Complete Results with Predictions\",\n",
    "            interactive=False,\n",
    "            wrap=True\n",
    "        )\n",
    "    \n",
    "    # Set up the prediction function\n",
    "    predict_btn.click(\n",
    "        fn=predict_churn,\n",
    "        inputs=[csv_input],\n",
    "        outputs=[\n",
    "            summary_output,\n",
    "            prob_dist_plot,\n",
    "            model_comparison_plot,\n",
    "            churn_risk_plot,\n",
    "            prediction_summary_plot,\n",
    "            results_table\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ## 💡 Model Information:\n",
    "    \n",
    "    **Risk Categories:**\n",
    "    - 🟢 **Low Risk (0-30%)**: Customers unlikely to churn\n",
    "    - 🟡 **Medium Risk (30-70%)**: Customers requiring attention  \n",
    "    - 🔴 **High Risk (70%+)**: Customers at high risk of churning\n",
    "    \n",
    "   \n",
    "    \"\"\")\n",
    "    \n",
    "    # Launch the app\n",
    "\n",
    "app.launch(\n",
    "    show_error=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
